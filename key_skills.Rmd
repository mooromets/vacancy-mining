---
title: "Key skills for DS role"
author: "Sergey Sambor"
date: "August 29, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libs, echo = FALSE}
library("RWeka")
library("tm")
library("SnowballC")

source("./requirements_transformer.R")
source("./sensible_terms.R")
```
Read jobs data
```{r read data}
conn <- file("./job/data.frame/27jobs.txt", open="r")
jobsData <- readLines(conn)
close(conn)

jobs <- VCorpus(VectorSource(jobsData))
# remove shortenings before stripping off punctuation
jobs <- requirements_transformer(jobs)
```
Find most frequent single-word terms
```{r single-word}
tdm1 <- TermDocumentMatrix(jobs, list(stopwords = TRUE, wordLengths=c(1,Inf)
                                      ))
head(findFreqTerms(tdm1, 5), 20)
```
It can be seen that most words are part of some multiple-word term, but they are meaningless as a single-word term.
Let's hide them.  
We arrange terms in the order of high occurancy
```{r}
sensible <- c()
for (i in seq(8, 2, by = -2)) {
  print (sprintf(" -- %i+ occurancies ----- ", i))
  thisMatch <- sensible_terms(findFreqTerms(tdm1, i))
  print(thisMatch <- setdiff(thisMatch, sensible))
  sensible <- c(sensible, thisMatch)
}
```
Now let's have a look at the most frequent two-word terms
```{r}
nGramTok <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
tdm2 <- 
  TermDocumentMatrix(jobs, list(tokenize = nGramTok, stopwords = TRUE, wordLengths=c(1,Inf)
                                ))
terms2 <- findFreqTerms(tdm2, 6)
head(terms2, 12)
```
"english write", "german good" "languag python"... We remove terms, that contain any word from meaningful single-word-terms
```{r}
# performs logical OR operation on all columns
frameOr <- function(x) {
  res <- rep(FALSE, dim(x)[1])
  for (i in 1:dim(x)[2])  res <- res | x[,i]
  res
}

# vector meanful contains terms like "ms" that are part of normal english words.
# We skip too short terms
longTerms <- sensible[nchar(sensible) > 3]

sensible2 <- c()
for (i in seq(10, 2, by = -2)) {
  print (sprintf(" -- %i+ occurancies ----- ", i))
  terms2 <- findFreqTerms(tdm2, i)
  index <- frameOr(as.data.frame(lapply(longTerms, grepl, x=terms2)))
  print(setdiff(terms2[!index], sensible2))
  meanful2 <- c(sensible2, terms2[!index])
}
```